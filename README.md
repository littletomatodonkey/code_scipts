## intro


## realization

1. Distilling Knowledge via Knowledge Review
    * paper: [https://jiaya.me/papers/kdreview_cvpr21.pdf](https://jiaya.me/papers/kdreview_cvpr21.pdf)
    * code: [https://github.com/Jia-Research-Lab/ReviewKD](https://github.com/Jia-Research-Lab/ReviewKD)
    * paddle realization: [link](./knowledge_review/)

2. Distilling Knowledge via Knowledge Review
    * paper: [https://arxiv.org/abs/2009.04759](https://arxiv.org/abs/2009.04759)
    * code: [https://github.com/nmaac/acon](https://github.com/nmaac/acon)
    * paddle realization: [link](./acon/)

3. Rethinking Soft Labels for Knowledge Distillation: A Bias-variance Tradeoff Perspective
    * paper: [https://arxiv.org/abs/2102.00650](https://arxiv.org/abs/2102.00650)
    * code: [https://github.com/bellymonster/Weighted-Soft-Label-Distillation](https://github.com/bellymonster/Weighted-Soft-Label-Distillation)
    * paddle realization: [link](./weighted_soft_label_distillation/)

* Exponential Moving Average
    * paper: [https://en.wikipedia.org/wiki/Moving_average](https://en.wikipedia.org/wiki/Moving_average)
    * code: so many, not listed here
    * gen ema model mannually: [link](./ema/)
